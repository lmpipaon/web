<!-- This is the markdown template for the final project of the Building AI course, 
created by Reaktor Innovations and University of Helsinki. 
Copy the template, paste it to your GitHub README and edit! -->

<h1>Intelligent Chlorination.<br>Implementing a Neural Network on an S1500 PLC</h1>
<p>Final project for the Building AI course</p>
<h2>Summary</h2>
<p>This project focuses on predicting the pulse rate of a chlorine dosing pump in a drinking water treatment plant based on water characteristics. An AI model will be developed to calculate the required pulse frequency.</p>
<p>The model will be deployed on a Siemens S1500 PLC.</p>
<h2>Background</h2>
<p>In water treatment plants, maintaining free chlorine levels is commonly managed using a classic PID (Proportional-Integral-Derivative) controller. However, the process requires a specific contact time between chlorine dosing and the measurement of free chlorine to ensure proper disinfection. This introduces a delay in the control loop, which can result in challenges such as instability, oscillations, or overshooting, potentially compromising water quality and dosing efficiency.</p>
<p>This project aims to implement an artificial intelligence based solution to predict the pulse frequency of sodium hypochlorite dosing pumps. While the PID controller will remain part of the closed loop, its role will shift to compensatory adjustments, focusing on fine-tuning the free chlorine level. By relying on predictive AI, the system will reduce fluctuations and enhance the stability of the dosing process.</p>
<p>Although linear regression could be used for this task, a small neural network is better suited to capture the breakpoint in chlorination and address non-linear behaviors effectively.</p>
<h2>The Treatment Plant</h2>
<p><img alt="treatment_plant_diagram" src="./images/treatment_plant_diagram.png" /></p>
<p>The treatment process begins with the dosing of coagulant, followed by filtration of the water. After that, the water undergoes ultraviolet (UV) treatment, and finally, it is chlorinated.</p>
<p>We monitor several parameters throughout the process, including:</p>
<ul>
<li>Turbidity of raw water</li>
<li>PPM of coagulant</li>
<li>UV percentage</li>
<li>Which dosing pump is operating</li>
<li>Hypochlorite tank level</li>
<li>pH levels</li>
<li>Free chlorine</li>
<li>Chlorine setpoint</li>
<li>Turbidity of treated water</li>
<li>Flow rate</li>
<li>Free chlorine treated water</li>
</ul>
<h2>Data sources</h2>
<p>We have an extensive dataset, with measurements recorded every 2 minutes over several years, including the parameters mentioned earlier. However, careful filtering is required to select only the data that can effectively train the neural network.</p>
<h3>Data Filtering</h3>
<ol>
<li>
<p>Initial Data Filtering:
At first, I filtered the data by discarding entries where the difference between the setpoint (desired free chlorine) and the measurement (measured free chlorine) was greater than 1% of the setpoint value. I then trained the neural network with the remaining data (as I will explain later). However, the data wasn't good enough, which led to convergence problems during training.</p>
</li>
<li>
<p>Alternative Data Filtering Approach:
To address these problems, I tried a different filtering method. Instead of discarding only the data where the difference between the setpoint and the measured value was greater than 1%, I also removed all entries where such differences occurred in the 5 readings before and after the current entry. This approach aimed to retain only the data that more accurately captured the relationship between water parameters and the pulse rate of the pumps.</p>
</li>
</ol>
<h2>Data Format Description</h2>
<p>The dataset is stored in a .csv file with a total of 8,463 rows, including the header row. The structure of the file is as follows:</p>
<p>| Pulses | TankLvl | ClSet | Pump | UV%   | Flow  | InfTurb | EffTurb | pH   | CoagPPM |
|--------|---------|-------|------|-------|-------|---------|---------|------|---------|
| 53.55  | 64.87   | 0.7   | 1    | 31.37 | 88.28 | 1.81    | 0.88    | 9.21 | 0       |
| 58.16  | 78.75   | 0.7   | 1    | 25.93 | 96.72 | 0.61    | 0.32    | 8.8  | 0       |
| 44.44  | 64.19   | 0.7   | 2    | 35.08 | 97.81 | 1.06    | 0.57    | 9.06 | 0       |
| 56.36  | 69.62   | 0.7   | 1    | 32.24 | 90.47 | 0.69    | 0.39    | 8.79 | 0       |
| ...    | ...     | ...   | ...  | ...   | ...   | ...     | ...     | ...  | ...     |</p>
<ul>
<li><strong>The first column</strong> (Output) represents the pump pulses This is the target variable the network is trained to predict.</li>
<li><strong>The next 9 columns</strong> correspond to the input features:</li>
<li><strong>1:</strong> Hypo. tank level</li>
<li><strong>2:</strong> Chlorine setpoint</li>
<li><strong>3:</strong> Dosing pump</li>
<li><strong>4:</strong> UV percentage</li>
<li><strong>5:</strong> Flow</li>
<li><strong>6:</strong> Influent turbidity</li>
<li><strong>7:</strong> Effluent turbidity</li>
<li><strong>8:</strong> pH</li>
<li><strong>9:</strong> Coagulant PPM</li>
</ul>
<p>The dataset file is located in the <strong>data</strong> folder under the name <strong>water_treatment_data.csv</strong>.</p>
<h2>Neural Network Structure</h2>
<p>The chosen neural network architecture will be simple to facilitate easy implementation on a Siemens S1500 PLC. I will experiment with a hidden layer with 6 neurons using a ReLU activation function, which is straightforward to implement. The output layer will consist of a single neuron without an activation function, allowing for continuous output across the full range.</p>
<p><img alt="NeuralNetworkDiagram" src="./images/NeuralNetworkDiagram.png" /></p>
<h2>Supervised Training of the Model</h2>
<p>The model training process will be carried out using Python, leveraging its powerful libraries such as TensorFlow or Keras for building and training the neural network. During this process, I have used the assistance of an AI tool (ChatGPT) to guide me through the coding.</p>
<p>The program must perform the following tasks:</p>
<p><strong>1. Data Preparation</strong>
   - Reads data from a CSV file, separates input features (9 columns) and the target variable (1 column).
   - Converts data to numeric and standardizes features using StandardScaler to improve model performance.</p>
<p><strong>2. Model Creation</strong>
   - Defines a simple neural network with:
     - A hidden layer (6 neurons, ReLU activation).
     - A dropout layer that randomly disables 20% of the neurons in the hidden layer to prevent overfitting.
     - A output neuron (linear activation for regression).
   - Uses adam optimizer, mean squared error (MSE) as the loss function, and mean absolute error (MAE) as a metric.</p>
<p><strong>3. Training</strong>
   - Splits data into training (80%) and validation (20%) sets using scikit-learn's train_test_split.
   - Trains the model with TensorFlow/Keras, applying backpropagation and Early Stopping to avoid overfitting.
   - Tested multiple configurations and techniques to optimize performance, including:
     - Dropout layers.
     - K-fold Cross-Validation
     - Different dataset splits.
     - Tuning the number of epochs and batch size.</p>
<p><strong>4. Evaluation</strong>
    - Assesses the model on the validation set using MSE, MAE, and R<sup>2</sup>.</p>
<p><strong>5. Visualization</strong>
   - Creates graphs to evaluate performance, including loss curves, scatter plots of predictions vs. actual values, residual distributions, and line plots.</p>
<p><strong>6. Exporting Results</strong>
   - Extracts weights, biases, and scaling parameters (mean and standard deviation) from the model and displays them in a format that can be directly copied and pasted into a TIA Portal Data Block.</p>
<p>The program is available in the <strong>src</strong> folder under the name <strong>train_neural_network.py</strong>.</p>
<h2>Implementing the Neural Network in a Siemens S7-1500 PLC</h2>
<p><strong>Hidden Layer Neurons:</strong> These neurons have 9 input connections, and they use the ReLU (Rectified Linear Unit) activation function to introduce non-linearity into the network, allowing it to learn complex patterns in the data.
  -  <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/HIDDEN_NEURON.pdf">Hidden Neuron</a></p>
<p><strong>Output Layer Neurons:</strong> These neurons have 6 input connections and do not use an activation function, as the output is a linear result based on the weighted sum of inputs.
  - <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/OUTPUT_NEURON.pdf">Output Neuron</a></p>
<p><strong>Normalization:</strong> Before feeding the data into the network, the input features must be normalized to ensure that the scale of the input values does not interfere with the learning process
  - <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/NORMALIZATION.pdf">Normalization</a></p>
<p><strong>Initialization:</strong> At the beginning of the program, within the FishScan system, it is essential to load the weights, biases, and normalization data into their respective Instance Data Blocks (DBs). These blocks will hold the trained weights and biases of the neural network, as well as the normalization parameters (mean and standard deviation) used during training.
   - <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/NEURAL_NETWORK_INITIALIZATION.pdf">Neural Network Initialization</a>
   - <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/NEURAL_NETWORK_WEIGHTS_BIASES_NORMALIZATION.pdf">Neural Network weights, biases and normalization data</a><br>
(The training process of the neural network has been implemented in such a way that the results can be directly copied and pasted into a database in TIA Portal, facilitating its use in automation systems.)</p>
<p><strong>Neural Network:</strong> Finally, a function will be responsible for executing the following steps: Normalize the 9 Input Features, Calculate the Hidden Layer Neurons, Calculate the Output Neuron.
- <a href="https://github.com/lmpipaon/Smart-Chlorination/blob/main/PLC/NEURAL_NETWORK.pdf">Neural Network</a></p>
<p>This function will be called every second from the main program</p>
<h2>Integration with the Existing PID Controller</h2>
<p>To ensure a smooth transition and maintain stability in the chlorine dosing process, the existing PID controller remains part of the control loop, operating alongside the neural network. The outputs of both systems are combined to calculate the final pulse rate for the dosing pump:</p>
<p><strong>Combining Outputs:</strong>
The output of the neural network is added to the output of the PID controller. The neural network predicts the required pulse frequency based on water parameters, providing a rapid adjustment to the dosing process. The PID controller fine-tunes the free chlorine level by compensating for any residual errors.</p>
<p><strong>Delay Compensation:</strong>
In the chlorine dosing system, there is an inherent delay of approximately 9 minutes between the time chlorine is dosed and when its effect is measured at the free chlorine sensor.</p>
<p>To prevent the PID controller from attempting to compensate for differences that do not yet exist (as the neural network adjusts instantly to the new setpoint), a delay of 9 minutes is introduced at the setpoint input to the PID controller.
This ensures that the PID controller reacts only to actual deviations in the free chlorine level, avoiding unnecessary oscillations and maintaining system stability.
By combining the predictive capabilities of the neural network with the PID controller's fine-tuning adjustments and introducing delay compensation, the system achieves a more stable and efficient chlorine dosing process.</p>
<h2>Neural Network Output Simulator for Chlorine Dosing</h2>
<p>I made this interactive <a href="https://lmpipaon.github.io/web/playing_NN.html">web tool</a> for fun! You can enter water parameters and see how the neural network calculates the pump pulses. Try it and see how it works!</p>